// api/index.js
export default async function handler(req, res) {
  // 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ (CORS) ‚Äî —á—Ç–æ–±—ã –±—Ä–∞—É–∑–µ—Ä –Ω–µ —Ä—É–≥–∞–ª—Å—è
  res.setHeader('Access-Control-Allow-Origin', '*');
  res.setHeader('Access-Control-Allow-Methods', 'GET, POST, OPTIONS');
  res.setHeader('Access-Control-Allow-Headers', 'Content-Type, Authorization');

  // –ï—Å–ª–∏ –±—Ä–∞—É–∑–µ—Ä –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø (OPTIONS)
  if (req.method === 'OPTIONS') {
    return res.status(200).end();
  }

  // 2. –¢–≤–æ–π –∫–ª—é—á Groq
  const GROQ_KEY = "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";

  try {
    // –ß–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    const { messages, model, temperature } = req.body || {};

    // –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç, –≤–µ—Ä–Ω–µ–º —Å—Ç–∞—Ç—É—Å
    if (!messages) {
      return res.status(200).json({ status: "BotHost API is Online üöÄ" });
    }

    // –í—ã–±–∏—Ä–∞–µ–º –º–æ–¥–µ–ª—å
    const modelMap = {
      "gpt-4o": "llama-3.1-70b-versatile", 
      "llama-3.1-405b": "llama-3.1-405b-reasoning",
      "llama-3.1-70b": "llama-3.1-70b-versatile",
      "mixtral": "mixtral-8x7b-32768"
    };
    
    const targetModel = modelMap[model] || "llama-3.1-70b-versatile";

    // 3. –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –≤ Groq
    const groqResponse = await fetch("https://api.groq.com/openai/v1/chat/completions", {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${GROQ_KEY}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        messages: messages,
        model: targetModel,
        temperature: temperature || 0.7,
        max_tokens: 4096,
        stream: false
      }),
    });

    const data = await groqResponse.json();

    // –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ç–≤–µ—Ç –Ω–∞ —Å–∞–π—Ç
    return res.status(200).json(data);

  } catch (error) {
    return res.status(500).json({ error: error.message });
  }
}
